{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quellen: https://microsoft.github.io/presidio/installation/\n",
    "#          https://microsoft.github.io/presidio/getting_started/\n",
    "#          https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/predefined_recognizers/stanza_recognizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer import PatternRecognizer\n",
    "from typing import List\n",
    "from presidio_analyzer import EntityRecognizer, RecognizerResult\n",
    "from presidio_analyzer.nlp_engine import NlpArtifacts\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_analyzer.nlp_engine import StanzaNlpEngine\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "[type: PHONE_NUMBER, start: 19, end: 31, score: 0.75]\n",
      "-----------------------------------------------\n",
      "text: My phone number is <PHONE_NUMBER>\n",
      "items:\n",
      "[\n",
      "    {'start': 19, 'end': 33, 'entity_type': 'PHONE_NUMBER', 'text': '<PHONE_NUMBER>', 'operator': 'replace'}\n",
      "]\n",
      "\n",
      "-----------------------------------------------\n",
      "[type: PERSON, start: 16, end: 21, score: 0.85, type: PHONE_NUMBER, start: 46, end: 58, score: 0.75]\n"
     ]
    }
   ],
   "source": [
    "text=\"My phone number is 212-555-5555\"\n",
    "\n",
    "# Set up the engine, loads the NLP module (spaCy model by default) \n",
    "# and other PII recognizers\n",
    "analyzer = AnalyzerEngine()\n",
    "\n",
    "# Call analyzer to get results\n",
    "results = analyzer.analyze(text=text,\n",
    "                           entities=[\"PHONE_NUMBER\"],\n",
    "                           language='en')\n",
    "print(results)\n",
    "print(f\"-----------------------------------------------\")\n",
    "\n",
    "# Analyzer results are passed to the AnonymizerEngine for anonymization\n",
    "\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
    "\n",
    "print(anonymized_text)\n",
    "print(f\"-----------------------------------------------\")\n",
    "\n",
    "text = \"His name is Mr. Jones and his phone number is 212-555-5555\"\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer_results = analyzer.analyze(text=text, language=\"en\")\n",
    "\n",
    "print(analyzer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deny-list recognizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " [type: TITLE, start: 10, end: 19, score: 1.0]\n",
      "-----------------------------------------------\n",
      "Results:\n",
      "[type: TITLE, start: 10, end: 19, score: 1.0, type: PERSON, start: 20, end: 24, score: 0.85]\n",
      "-----------------------------------------------\n",
      "Identified these PII entities:\n",
      "- Professor as TITLE\n",
      "- Plum as PERSON\n"
     ]
    }
   ],
   "source": [
    "titles_list = [\n",
    "    \"Sir\",\n",
    "    \"Ma'am\",\n",
    "    \"Madam\",\n",
    "    \"Mr.\",\n",
    "    \"Mrs.\",\n",
    "    \"Ms.\",\n",
    "    \"Miss\",\n",
    "    \"Dr.\",\n",
    "    \"Professor\",\n",
    "]\n",
    "\n",
    "titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list)\n",
    "text1 = \"I suspect Professor Plum, in the Dining Room, with the candlestick\"\n",
    "result = titles_recognizer.analyze(text1, entities=[\"TITLE\"])\n",
    "print(f\"Result:\\n {result}\")\n",
    "print(f\"-----------------------------------------------\")\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.registry.add_recognizer(titles_recognizer)\n",
    "\n",
    "results = analyzer.analyze(text=text1, language=\"en\")\n",
    "print(\"Results:\")\n",
    "print(results)\n",
    "print(f\"-----------------------------------------------\")\n",
    "\n",
    "print(\"Identified these PII entities:\")\n",
    "for result in results:\n",
    "    print(f\"- {text1[result.start:result.end]} as {result.entity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule based logic recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "type: PERSON, start: 0, end: 7, score: 0.85\n",
      "type: NUMBER, start: 17, end: 21, score: 0.7\n",
      "type: NUMBER, start: 22, end: 24, score: 0.7\n"
     ]
    }
   ],
   "source": [
    "class NumbersRecognizer(EntityRecognizer):\n",
    "\n",
    "    expected_confidence_level = 0.7  # expected confidence level for this recognizer\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"No loading is required.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def analyze(\n",
    "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n",
    "    ) -> List[RecognizerResult]:\n",
    "        \"\"\"\n",
    "        Analyzes test to find tokens which represent numbers (either 123 or One Two Three).\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        # iterate over the spaCy tokens, and call `token.like_num`\n",
    "        for token in nlp_artifacts.tokens:\n",
    "            if token.like_num:\n",
    "                result = RecognizerResult(\n",
    "                    entity_type=\"NUMBER\",\n",
    "                    start=token.idx,\n",
    "                    end=token.idx + len(token),\n",
    "                    score=self.expected_confidence_level,\n",
    "                )\n",
    "                results.append(result)\n",
    "        return results\n",
    "\n",
    "\n",
    "# Instantiate the new NumbersRecognizer:\n",
    "new_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"])\n",
    "\n",
    "text3 = \"Roberto lives in Five 10 Broad st.\"\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.registry.add_recognizer(new_numbers_recognizer)\n",
    "\n",
    "numbers_results2 = analyzer.analyze(text=text3, language=\"en\")\n",
    "print(\"Results:\")\n",
    "print(\"\\n\".join([str(res) for res in numbers_results2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supporting new models and languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from English request:\n",
      "[type: PERSON, start: 11, end: 17, score: 0.85]\n"
     ]
    }
   ],
   "source": [
    "# Create configuration containing engine name and models\n",
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [\n",
    "        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create NLP engine based on configuration\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine_with_spanish = provider.create_engine()\n",
    "\n",
    "# Pass the created NLP engine and supported_languages to the AnalyzerEngine\n",
    "analyzer = AnalyzerEngine(\n",
    "    nlp_engine=nlp_engine_with_spanish, supported_languages=[\"en\"]\n",
    ")\n",
    "\n",
    "# Analyze in different languages\n",
    "results_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\n",
    "print(\"Results from English request:\")\n",
    "print(results_english)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
